[{"authors":["admin"],"categories":null,"content":"I am a PhD student at Georgia Tech, advised by Prof. Cassie Mitchell. My research focuses on developing methods to determine risk factors of disease progression using text-mined knowledge graphs and deep learning on clinical data.\nDuring my MS, I was advised by Prof. Jimeng Sun. My research focused on interpretable modeling for clinical decision support systems. I have been working on automatic sleep staging which is used to evaluate the quality of sleep and diagnose sleep disorders. The aim is to design robust, interpretable models for automatic sleep staging by utilizing knowledge distilled from latent embeddings of deep learning models to enhance computational models resulting from rules used by experts in the field. I have also worked on iterative machine teaching which aims to generate the ideal sequence of samples to sequentially send to a black-box learner. During summer \u0026lsquo;20, I was a Fellow for National Security Innovation Network at Department of Defence, working on contact tracing and physiological monitoring for COVID-19. Previously, I worked at Applied Open Architectures Branch, Electronic Systems Lab of Georgia Tech Research Institute (GTRI) focusing on data transfer through a time sensitive ethernet network carrying both deterministic and regular TCP/IP data over the same channel. Specifically, my focus was to utilize Audio Video Bridging (AVB), a deterministic ethernet protocol on embedded systems connected to an AVB switch.\nDuring my undergraduate studies, I worked on real-time beat tracking from music on an embedded system. We built an embedded system which tracks beats from music acquired through a microphone and demonstrates the output through a band of dancing skeletons in real-time. It was the result of our participation in the IEEE Signal Processing Cup 2017. The video is available here. I also worked on an autonomous arm manipulator.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a PhD student at Georgia Tech, advised by Prof. Cassie Mitchell. My research focuses on developing methods to determine risk factors of disease progression using text-mined knowledge graphs and deep learning on clinical data.\nDuring my MS, I was advised by Prof. Jimeng Sun. My research focused on interpretable modeling for clinical decision support systems. I have been working on automatic sleep staging which is used to evaluate the quality of sleep and diagnose sleep disorders.","tags":null,"title":"Irfan Al-Hussaini","type":"authors"},{"authors":[],"categories":[],"content":"","date":1577691435,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577691435,"objectID":"45c30c6f03839b8611e6bc39587fdd6a","permalink":"/project/sleep/","publishdate":"2019-12-30T13:37:15+06:00","relpermalink":"/project/sleep/","section":"project","summary":"Interpretable sleep staging by utilizing knowledge distilled from deep learning models to enhance computational models resulting from rules used by expert in the field","tags":["interpretability","deep-learning","prototype-learning","machine-learning","clinical-decision-making"],"title":"Interpretable Sleep Staging","type":"project"},{"authors":[],"categories":[],"content":"","date":1577690292,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577690292,"objectID":"b22c0b695097950a3ff34524fe5771bc","permalink":"/project/vision/","publishdate":"2019-12-30T13:18:12+06:00","relpermalink":"/project/vision/","section":"project","summary":"Developed the energy functional and level set formulation with gradient descent of Chan Vese Algorithm and implemented binary image segmentation and tested robustness in the presence of different noises.","tags":["computer-vision","image-segmentation"],"title":"Image Segmentation using a Variational PDE Model","type":"project"},{"authors":[],"categories":[],"content":"","date":1577690283,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577690283,"objectID":"f6143dffba2f036cf73abd4a22782e84","permalink":"/project/star/","publishdate":"2019-12-30T13:18:03+06:00","relpermalink":"/project/star/","section":"project","summary":"Action and winner prediction based on current game state in Startcraft II. Evaluation occurs using selected frame in the uploaded replay.","tags":["data-analytics","data-visualization"],"title":"Starlytics: Starcraft II Action and Winner Prediction","type":"project"},{"authors":[],"categories":[],"content":"","date":1577690274,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577690274,"objectID":"16f291094e5e8ce2174ed8874d9e9ce6","permalink":"/project/binary/","publishdate":"2019-12-30T13:17:54+06:00","relpermalink":"/project/binary/","section":"project","summary":"Static and Dynamic Analysis of Malware Binaries using IDA Pro and Pin respectively","tags":["binary-analysis","ida-pro","pin","malware-analysis"],"title":"Binary Analysis","type":"project"},{"authors":[],"categories":[],"content":"","date":1577690268,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577690268,"objectID":"3c24b9fa87982b61c533f372e85b043f","permalink":"/project/beat/","publishdate":"2019-12-30T13:17:48+06:00","relpermalink":"/project/beat/","section":"project","summary":"Real-time beat tracking from audio streams originating from a microphone and a visualization of the beats using a band of dancing skeletons.","tags":["music-information-retrieval","dynamic-programming","real-time","embedded-system"],"title":"Music Beat Tracking","type":"project"},{"authors":[],"categories":[],"content":"","date":1577689830,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577689830,"objectID":"52063d651854ee44de920d37b63cd29a","permalink":"/project/arm/","publishdate":"2019-12-30T13:10:30+06:00","relpermalink":"/project/arm/","section":"project","summary":"Arm Manipulator featuring wake-word detection using two fold dynamic programming and off-the shelf object recognition","tags":["arm-manipulator","dynamic-time-warping","speech-recognition","object-recognition"],"title":"Autonomous Arm Manipulator","type":"project"},{"authors":["Irfan Al-Hussaini","Cao Xiao","Brandon Westover","Jimeng Sun"],"categories":null,"content":"","date":1559948438,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559948438,"objectID":"b6961d5b7801c5c45cec3d53a3f32675","permalink":"/publication/mlhc/","publishdate":"2019-06-07T18:00:38-05:00","relpermalink":"/publication/mlhc/","section":"publication","summary":"Sleep staging is a crucial task for diagnosing sleep disorders. It is tedious and complex as it can take a trained expert several hours to annotate just one patient’s polysomnogram (PSG) from a single night. Although deep learning models have demonstrated state-of-the-art performance in automating sleep staging, interpretability which defines other desiderata, has largely remained unexplored. In this study, we propose Sleep staging via Prototypes from Expert Rules (SLEEPER), which combines deep learning models with expert defined rules using a prototype learning framework to generate simple interpretable models. In particular, SLEEPER utilizes sleep scoring rules and expert defined features to derive prototypes which are embeddings of PSG data fragments via convolutional neural networks. The final models are simple interpretable models like a shallow decision tree defined over those phenotypes. We evaluated SLEEPER using two PSG datasets collected from sleep studies and demonstrated that SLEEPER could provide accurate sleep stage classification comparable to human experts and deep neural networks with about 85% ROC-AUC and .7 κ.","tags":["interpretability","machine-learning","clinical-decision-making","deep-learning","prototype-learning"],"title":"SLEEPER: interpretable Sleep staging via Prototypes from Expert Rules","type":"publication"},{"authors":["Irfan Al-Hussaini","Ahmed Imtiaz Humayun","Shariful Islam Foysal","Samiul Alam","Abdullah Al Masud","Arafat Mahmud","Rakibul Islam Chowdhury","Nabil Ibtehaz","Sums Uz Zaman","Rakib Hyder","Sayeed Shafayet Chowdhury","Mohammad Ariful Haque"],"categories":null,"content":"","date":1543186838,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543186838,"objectID":"4dd22f74fbd2ec37cfa5bf12334c6f4d","permalink":"/publication/mipr/","publishdate":"2018-11-25T18:00:38-05:00","relpermalink":"/publication/mipr/","section":"publication","summary":"Beat tracking from music signals has significant importance in multimedia information retrieval systems, especially in cover song detection. A predictive real-time beat tracking system can also be used to assist musicians performing live. In this paper we present a real-time beat tracking algorithm, fast enough to be implemented on an embedded system. The onset of a note is detected using a maximum filter approach that suppresses the effect of vibrato. Beats are predicted a second in advance using a causal variant of Dynamic Programming. We have employed an onset memoization algorithm, to reduce the computational resources required. Raspberry Pi was chosen as our preferred development board. We have demonstrated through experimental results that the proposed approach can satisfactorily estimate beat positions from a music signal in real-time with an average continuity score (AMLt) of 0.67.","tags":["music-information-retrieval","dynamic-programming","real-time","embedded-system"],"title":"Predictive Real-Time Beat Tracking from Music for Embedded Application","type":"publication"},{"authors":["Irfan Al-Hussaini","Zubayer Islam","Antik Mallick","Md. Ekramul Hoque"],"categories":null,"content":"","date":1511650838,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511650838,"objectID":"92bf27979e07a0216281613f92c9c7ee","permalink":"/publication/icsipa/","publishdate":"2017-11-25T18:00:38-05:00","relpermalink":"/publication/icsipa/","section":"publication","summary":"In this paper, we propound a command processing mechanism for an autonomous arm manipulator using real-time speech and images. We propose a novel two-stage speech recognition algorithm using two-fold Dynamic Time Warping in each stage. Real-time wake-up word recognition is followed by offline command recognition using k-means. Since high precision is paramount in any control system activation mechanism, a restrictive threshold is set to gain a precision of 1. This alleviates the problem of accidental triggering of the control system. Object recognition and classification is performed by matching features resulting from a local feature detector and descriptor. The algorithm controls an arm manipulator with 5 degrees of freedom.","tags":["arm-manipulator","dynamic-time-warping","speech-recognition","object-recognition"],"title":"Object recognition and real-time spoken word recognition using two-fold dynamic time warping for autonomous arm manipulator","type":"publication"}]